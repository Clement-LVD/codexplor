---
title: "Turn a programming project into a corpus"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Turn a programming project into a corpus}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(codexplor)

```

## construct_corpus

**Minimum Requirements.** `codexplor::construct_corpus` turn a programming project into a text-mining corpus, given :

- folder(s) path(s) and/or github repo(s) of the project ;
- and programming language(s) - default is `'R'`.

**Supported languages.** By default `construct_corpus` will analyze .R files. One or several `languages` could be indicated. Recognized languages are `r paste0(names(get_def_regex_by_language()) , collapse = ", ")`. 

## Examples


```{r example, echo=TRUE}

library(codexplor)

# 1) Construct a corpus without a Citations network
  corpus <- construct_corpus(languages = "R"
                           , repos =  "clement-LVD/codexplor")
  
  str(corpus, max.level = 1) 
  
```

     # Example : several local folders and repos
    corpus <- construct_corpus(c("~", "M:/") languages = "R"
    , repos =  c("clement-LVD/codexplor","tidyverse/stringr"))
   
    # Example : several languages
    corpus_py <- construct_corpus(repos = "secdev/scapy"
    , languages = c("Python", "R"), .verbose = T) #take a while


## Understand the corpus.list
**List of dataframes.** `construct_corpus` return a `corpus.list` object, a standard `list` of 4 dataframes : 

- `codes` (classes `corpus.lines` & `data.frame`)
- `comments` (classes `corpus.lines` & `data.frame`)
- `files` (classes `corpus.nodelist` & `data.frame`)
- `functions` (classes `corpus.nodelist` & `data.frame`)
- `files.network` (classes `citations.network`, `internal.dependencies` & `data.frame`)
- and a `functions.network` (classes `citations.network`, `internal.dependencies` & `data.frame`)


**Returned df.** This `corpus.list` of df offers insights on the programming project, at various levels :


<!-- - The `files` `data.frame` contains the files path and/or url, and overall text-mining metrics about each files of the corpus (e.g., number of characters, words count; number of functions within the file). -->

<!-- - The `functions` `data.frame` contains the functions names and text-mining metrics about these functions. -->

<!-- - The 2 `corpus.lines` `data.frame` are related to `comments` or `codes` lines (file path and content of each lines, line number, and text-mining metrics related to each lines).  -->

<!-- - The 2 `citations.network` of `internal.dependencies` are a `files.network` and a `functions.network` within the corpus.  -->


```{r examples, echo=FALSE}

knitr::kable(data.frame(Name = c("`codes`", "`comments`", "`functions`", "`files`", "`files.network`" , "`functions.network`")
, Level = c("Line of code" , "Commented line","Function-level metrics"
              , "File-level metrics"
              , "Network (file-level)", "Network (function-level)" )
 , e.g. = c( "Identify problematics lines, e.g., longest ones", '.', "e.g., quantify the longest function and those with multiple internal dependencies", "e.g., quantify number of functions within files and critical internal dependencies", "Documents network / add metrics to the `files` df", "Functions network / add metrics to the `functions` df" )
))

```

In order to understand the `citations.network` of `internal.dependencies`, see the [vignette of `citations.network` `dataframe`](https://clement-lvd.github.io/codexplor/articles/vignette_citations.network_df_of_internal.dependencies.html)
