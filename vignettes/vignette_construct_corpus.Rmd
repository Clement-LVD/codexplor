---
title: "Turn a programming project into a corpus"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Turn a programming project into a corpus}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

```

# Constructing your corpus
`codexplor` offer a standardized protocol to turn a programming project into a text-mining corpus, by providing to `construct_corpus` language(s) to analyze, folder(s) path(s) and/or github repo(s).

```{r echo=TRUE, eval = T}
library(codexplor)

 # 1) Construct a corpus and a Citations network
  net <- get_doc_network_from_project(folders = ("~"), languages = "R")
   # return a corpus.list object with 2 corpus.line, 1 corpus.nodelist & 1 citations.network

  # since this readme is executed from a repo we ask for a "local" folder path ("R/")
  # At home you'll have the same results with the codexplor github repo : 
  # net <-  get_doc_network_from_project(repos = "clement-LVD/codexplor", languages = "R")

  str(net, max.level = 1) 
  
```


    corpus <- construct_corpus("~", "tidyverse/stringr", languages = "R")

    # Return a standard `list` of `df` (a `corpus.list` object)
    
    corpus_py <- construct_corpus(repos = "secdev/scapy", languages = "Python", .verbose = T) #take a while

This function will compute some text-mining metrics within each line and within document-level (e.g., number of characters, words count).

### About default patterns associated with each language
Standardized patterns are used to construct a corpus. Each of the `languages` supported by `construct_corpus` involve some patterns for :

```{r table-operations-construct-corpus, echo=FALSE}

steps <- data.frame(Step = c("Read the files of the local folder(s) and/or github public repo(s) accordingly to their extension"  
, "Separate commented lines from code lines"                    
 , "Extract a 1st matched-text within the codes lines, accordingly to a pattern"

)
 , Examples = c('e.g., "R" language is associated with "`.R`" files and with a filtering pattern (e.g., files with "`test-`", "`vignettes`", "`Rcheck`" in their full names are excluded)'   
, 'e.g., R & Python files generally have each commented lines that begin with "`#`", others languages should have commented blocks separeted on several lines (e.g., `/* [comments] */`'
  , 'e.g.,  default pattern is catching the names of the functions defined within a file, e.g., for the R programming language : the name is before a "`<- function(`" instruction'
)

)

colnames(steps) <- c("Steps", "Examples of pattern associated with language(s)")

knitr::kable(steps,row.names = T )

```

By default `construct_corpus` try to analyze .R files. One or several `languages` could be passed to `construct_corpus`. Planned languages are : `r paste0(names(get_def_regex_by_language()), collapse = ", ")`

### Function call that are non-supported
Some way of writing a program are not fully supported, such as :

**Python instantiated methods.** The instantiated Python methods (i.e. `obj.method()`) are not supported for now.

```{r eval = F }
#  Python code herafter : unmatched function called
class A:
    def method(self):
        return "My custom method"

obj = A()
obj.method()  # codexplor don't see that internal dependancy since the method() had a prefix ("obj.")
#return : 'My custom method'
```

### About duplicated lines associated with 1st matches
`construct_corpus` perform a 1st text-extraction, accordingly to a pattern. During this 1st matches extraction, lines are duplicated *when several matches are found on the same line*. 

> For example, by default, the names of functions defined in the files of the project are extracted during the 1st match operated by `construct_corpus`. If a file have several function defined *within the same line*, such a line will be duplicated in the returned `df`, with several 'matches' entries along these lines and an identical line_number. 
