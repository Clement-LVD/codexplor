# Construire l'URL de l'API GitHub
repo <- gsub(pattern = "/$", replacement = "", repo)
if (grepl("^https?://",repo)) {
api_url <- paste0(repo, "?recursive=1")
base_url <- repo
} else {
base_url <-paste0("https://api.github.com/repos/", repo, "/git/trees/", branch)
api_url <- paste0(base_url, "?recursive=1")
}
# Lire le JSON depuis GitHub
json_data <- tryCatch({
paste(readLines(api_url, warn = FALSE), collapse = "")
}, error = function(e) {
warning("Erreur lors de la récupération des données. Vérifiez l'URL ou les permissions d'accès.")
return(NULL)
})
# Vérifier si la réponse contient des fichiers
if (is.null(json_data) || !grepl('"path":', json_data)) {
stop("Aucun fichier trouvé. Vérifiez le repo ou le pattern utilisé.")
}
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(pattern = paste0('"path":"([^"]+', pattern, ')"'), json_data, ignore.case = TRUE)))
file_paths <- gsub('"path":"', "", file_paths)  # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)         # Nettoyer les guillemets restants
file_paths
# Construire les URLs complètes des fichiers bruts
raw_urls <- paste0(base_url, "/", file_paths)
raw_urls
#' @param pattern **(character)** A regex pattern to filter files (default is `"\\.R$"`, meaning R scripts).
#'
#' @return A character vector of URLs pointing to the raw content of the matching files.
#' @export
#'
#' @examples
#' \dontrun{
#' url1 <- get_github_filespath(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R$")
#' urls <- get_github_filespath(repo = "https://api.github.com/repos/tidyverse/ggplot2/git/trees/main")
#' }
get_github_filespath <- function(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R", pointer_i = 0) {
# Construire l'URL de l'API GitHub
repo <- gsub(pattern = "/$", replacement = "", repo)
if (grepl("^https?://",repo)) {
api_url <- paste0(repo, "?recursive=1")
base_url <- repo
} else {
base_url <-paste0("https://api.github.com/repos/", repo, "/git/trees/", branch)
api_url <- paste0(base_url, "?recursive=1")
}
# Lire le JSON depuis GitHub
json_data <- tryCatch({
paste(readLines(api_url, warn = FALSE), collapse = "")
}, error = function(e) {
warning("Erreur lors de la récupération des données. Vérifiez l'URL ou les permissions d'accès.")
return(NULL)
})
# Vérifier si la réponse contient des fichiers
if (is.null(json_data) || !grepl('"path":', json_data)) {
stop("Aucun fichier trouvé. Vérifiez le repo ou le pattern utilisé.")
}
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(pattern = paste0('"path":"([^"]+', pattern, ')"'), json_data, ignore.case = TRUE)))
file_paths <- gsub('"path":"', "", file_paths)  # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)         # Nettoyer les guillemets restants
# Construire les URLs complètes des fichiers bruts
raw_urls <- paste0(base_url, "/", file_paths)
return(raw_urls)
}
url1 <- get_github_filespath(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R$")
url1
urls <- get_github_filespath(repo = "https://api.github.com/repos/tidyverse/ggplot2/git/trees/main")
urls
#' @param branch **(character)** The branch to scan for files. Default is `"main"`.
#' @param pattern **(character)** A regex pattern to filter files (default is `"\\.R"`, meaning R scripts).
#'
#' @return A character vector of URLs pointing to the raw content of the matching files.
#' @export
#'
#' @examples
#' \dontrun{
#' readr_fp <- get_github_filespath(owner_slash_repo = "tidyverse/readr/", pattern = "\\.R")
#' }
get_github_filespath <- function(repo = "tidyverse/ggplot", branch = "main", pattern = "\\.R") {
# construct an url to api.github :
if (grepl("^https?://", repo)) {
direct_access = T# we retrieve that hereafter for crafting the url!
api_url <- paste0(repo,  "?recursive=1")  #use URL passed
} else {direct_access =
api_url <- paste0("https://api.github.com/repos/",repo, "/git/trees/", branch, "?recursive=1") }
# Lire le JSON en texte brut
json_data <- paste(readLines(api_url, warn = FALSE), collapse = "")
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(ignore.case = T , pattern = paste0('"path":"[^"]+', pattern, '"'), text = json_data)))
file_paths <- gsub('"path":"', "", file_paths) # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)       # Nettoyer les guillemets restants
# Construire les URLs complètes des fichiers bruts
raw_urls <- paste0( "https://raw.githubusercontent.com/" , repo, "/", branch, "/", file_paths)
if(direct_access){ raw_urls <- paste0( repo ,file_paths) }
return(raw_urls)
}
get_github_filespath(repo = "tidyverse/readr/", pattern = "\\.R")
#' @param branch **(character)** The branch to scan for files. Default is `"main"`.
#' @param pattern **(character)** A regex pattern to filter files (default is `"\\.R"`, meaning R scripts).
#'
#' @return A character vector of URLs pointing to the raw content of the matching files.
#' @export
#'
#' @examples
#' \dontrun{
#' readr_fp <- get_github_filespath(repo = "tidyverse/readr/", pattern = "\\.R")
#' }
get_github_filespath <- function(repo = "tidyverse/ggplot", branch = "main", pattern = "\\.R") {
# construct an url to api.github :
if (grepl("^https?://", repo)) {
direct_access = T# we retrieve that hereafter for crafting the url!
api_url <- paste0(repo,  "?recursive=1")  #use URL passed
} else {direct_access =
api_url <- paste0("https://api.github.com/repos",repo, "/git/trees/", branch, "?recursive=1") }
# Lire le JSON en texte brut
json_data <- paste(readLines(api_url, warn = FALSE), collapse = "")
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(ignore.case = T , pattern = paste0('"path":"[^"]+', pattern, '"'), text = json_data)))
file_paths <- gsub('"path":"', "", file_paths) # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)       # Nettoyer les guillemets restants
# Construire les URLs complètes des fichiers bruts
raw_urls <- paste0( "https://raw.githubusercontent.com/" , repo, "/", branch, "/", file_paths)
if(direct_access){ raw_urls <- paste0( repo ,file_paths) }
return(raw_urls)
}
get_github_filespath(repo = "tidyverse/readr/", pattern = "\\.R")
}
get_github_filespath(repo = "tidyverse/readr/", pattern = "\\.R")
repo
#' @param branch **(character)** The branch to scan for files. Default is `"main"`.
#' @param pattern **(character)** A regex pattern to filter files (default is `"\\.R"`, meaning R scripts).
#'
#' @return A character vector of URLs pointing to the raw content of the matching files.
#' @export
#'
#' @examples
#' \dontrun{
#' readr_fp <- get_github_filespath(repo = "tidyverse/readr/", pattern = "\\.R")
#' }
get_github_filespath <- function(repo = "tidyverse/ggplot", branch = "main", pattern = "\\.R") {
# construct an url to api.github :
if (grepl("^https?://", repo)) {
direct_access = T# we retrieve that hereafter for crafting the url!
api_url <- paste0(repo,  "?recursive=1")  #use URL passed
} else {direct_access =
api_url <- paste0("https://api.github.com/repos/",repo, "/git/trees/", branch, "?recursive=1") }
# Lire le JSON en texte brut
json_data <- paste(readLines(api_url, warn = FALSE), collapse = "")
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(ignore.case = T , pattern = paste0('"path":"[^"]+', pattern, '"'), text = json_data)))
file_paths <- gsub('"path":"', "", file_paths) # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)       # Nettoyer les guillemets restants
# Construire les URLs complètes des fichiers bruts
raw_urls <- paste0( "https://raw.githubusercontent.com/" , repo, "/", branch, "/", file_paths)
if(direct_access){ raw_urls <- paste0( repo ,file_paths) }
return(raw_urls)
}
get_github_filespath(repo = "tidyverse/readr/", pattern = "\\.R")
repo = "tidyverse/readr/"
# construct an url to api.github :
if (grepl("^https?://", repo)) {
direct_access = T# we retrieve that hereafter for crafting the url!
api_url <- paste0(repo,  "?recursive=1")  #use URL passed
} else {direct_access =
api_url <- paste0("https://api.github.com/repos/",repo, "/git/trees/", branch, "?recursive=1") }
api_url
repo
' readr_fp <- get_github_filespath(repo = "tidyverse/readr", pattern = "\\.R")
readr_fp <- get_github_filespath(repo = "tidyverse/readr", pattern = "\\.R")
readr_fp
#' @param branch **(character)** The branch to scan for files. Default is `"main"`.
#' @param pattern **(character)** A regex pattern to filter files (default is `"\\.R"`, meaning R scripts).
#'
#' @return A character vector of URLs pointing to the raw content of the matching files.
#' @export
#'
#' @examples
#' \dontrun{
#' readr_fp <- get_github_filespath(repo = "tidyverse/readr", pattern = "\\.R")
#' }
get_github_filespath <- function(repo = "tidyverse/ggplot", branch = "main", pattern = "\\.R") {
# construct an url to api.github :
if (grepl("^https?://", repo)) {
direct_access = T# we retrieve that hereafter for crafting the url!
api_url <- paste0(repo,  "?recursive=1")  #use URL passed
} else {direct_access = F
api_url <- paste0("https://api.github.com/repos/",repo, "/git/trees/", branch, "?recursive=1") }
# Lire le JSON en texte brut
json_data <- paste(readLines(api_url, warn = FALSE), collapse = "")
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(ignore.case = T , pattern = paste0('"path":"[^"]+', pattern, '"'), text = json_data)))
file_paths <- gsub('"path":"', "", file_paths) # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)       # Nettoyer les guillemets restants
# Construire les URLs complètes des fichiers bruts
raw_urls <- paste0( "https://raw.githubusercontent.com/" , repo, "/", branch, "/", file_paths)
if(direct_access){ raw_urls <- paste0( repo ,file_paths) }
return(raw_urls)
}
readr_fp <- get_github_filespath(repo = "tidyverse/readr", pattern = "\\.R")
readr_fp
#' @param branch **(character)** The branch to scan for files. Default is `"main"`.
#' @param pattern **(character)** A regex pattern to filter files (default is `"\\.R"`, meaning R scripts).
#'
#' @return A character vector of URLs pointing to the raw content of the matching files.
#' @export
#'
#' @examples
#' \dontrun{
#' readr_fp <- get_github_filespath(repo = "tidyverse/readr", pattern = "\\.R")
#' }
get_rawgithub_filespath <- function(repo = "tidyverse/ggplot", branch = "main", pattern = "\\.R") {
# construct an url to api.github :
if (grepl("^https?://", repo)) {
direct_access = T# we retrieve that hereafter for crafting the url!
api_url <- paste0(repo,  "?recursive=1")  #use URL passed
} else {direct_access = F
api_url <- paste0("https://api.github.com/repos/",repo, "/git/trees/", branch, "?recursive=1") }
# Lire le JSON en texte brut
json_data <- paste(readLines(api_url, warn = FALSE), collapse = "")
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(ignore.case = T , pattern = paste0('"path":"[^"]+', pattern, '"'), text = json_data)))
file_paths <- gsub('"path":"', "", file_paths) # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)       # Nettoyer les guillemets restants
# Construire les URLs complètes des fichiers bruts
raw_urls <- paste0( "https://raw.githubusercontent.com/" , repo, "/", branch, "/", file_paths)
if(direct_access){ raw_urls <- paste0( repo ,file_paths) }
return(raw_urls)
}
#' @param pattern **(character)** A regex pattern to filter files (default is `"\\.R$"`, meaning R scripts).
#'
#' @return A character vector of URLs pointing to the raw content of the matching files.
#' @export
#'
#' @examples
#' \dontrun{
#' url1 <- get_github_filespath(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R$")
#' urls <- get_github_filespath(repo = "https://api.github.com/repos/tidyverse/ggplot2/git/trees/main")
#' }
get_github_filespath <- function(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R", pointer_i = 0) {
# Construire l'URL de l'API GitHub
repo <- gsub(pattern = "/$", replacement = "", repo)
if (grepl("^https?://",repo)) {
api_url <- paste0(repo, "?recursive=1")
base_url <- repo
} else {
base_url <-paste0("https://api.github.com/repos/", repo, "/git/trees/", branch)
api_url <- paste0(base_url, "?recursive=1")
}
# Lire le JSON depuis GitHub
json_data <- tryCatch({
paste(readLines(api_url, warn = FALSE), collapse = "")
}, error = function(e) {
warning("Erreur lors de la récupération des données. Vérifiez l'URL ou les permissions d'accès.")
return(NULL)
})
# Vérifier si la réponse contient des fichiers
if (is.null(json_data) || !grepl('"path":', json_data)) {
stop("Aucun fichier trouvé. Vérifiez le repo ou le pattern utilisé.")
}
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(pattern = paste0('"path":"([^"]+', pattern, ')"'), json_data, ignore.case = TRUE)))
file_paths <- gsub('"path":"', "", file_paths)  # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)         # Nettoyer les guillemets restants
# Construire les URLs complètes des fichiers bruts
raw_urls <- paste0(base_url, "/", file_paths)
if(length(raw_urls) == 1) cat(raw_urls, "PROBLEEME ")
return(raw_urls)
}
url1 <- get_github_filespath(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R$")
}
# Construire l'URL de l'API GitHub
repo <- gsub(pattern = "/$", replacement = "", repo)
#' @param pattern **(character)** A regex pattern to filter files (default is `"\\.R$"`, meaning R scripts).
#'
#' @return A character vector of URLs pointing to the raw content of the matching files.
#' @export
#'
#' @examples
#' \dontrun{
#' url1 <- get_github_filespath(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R$")
#' urls <- get_github_filespath(repo = "https://api.github.com/repos/tidyverse/ggplot2/git/trees/main")
#' }
get_github_filespath <- function(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R", pointer_i = 0) {
# Construire l'URL de l'API GitHub
repo <- gsub(pattern = "/$", replacement = "", repo)
if (grepl("^https?://",repo)) {
api_url <- paste0(repo, "?recursive=1")
base_url <- repo
} else {
base_url <-paste0("https://api.github.com/repos/", repo, "/git/trees/", branch)
api_url <- paste0(base_url, "?recursive=1")
}
# Lire le JSON depuis GitHub
json_data <- tryCatch({
paste(readLines(api_url, warn = FALSE), collapse = "")
}, error = function(e) {
warning("Erreur lors de la récupération des données. Vérifiez l'URL ou les permissions d'accès.")
return(NULL)
})
# Vérifier si la réponse contient des fichiers
if (is.null(json_data) || !grepl('"path":', json_data)) {
stop("Aucun fichier trouvé. Vérifiez le repo ou le pattern utilisé.")
}
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(pattern = paste0('"path":"([^"]+', pattern, ')"'), json_data, ignore.case = TRUE)))
file_paths <- gsub('"path":"', "", file_paths)  # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)         # Nettoyer les guillemets restants
# Construire les URLs complètes des fichiers bruts
raw_urls <- paste0(base_url, "/", file_paths)
if(length(raw_urls) == 1) {
if(pointer_i == 0) return(get_github_filespath(repo = raw_urls) )
stop("PROBLEME !")
}
return(raw_urls)
}
url1 <- get_github_filespath(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R$")
url1
#' @return A character vector of URLs pointing to the raw content of the matching files.
#' @export
#'
#' @examples
#' \dontrun{
#' url1 <- get_github_filespath(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R$")
#' urls <- get_github_filespath(repo = "https://api.github.com/repos/tidyverse/ggplot2/git/trees/main")
#' }
get_github_filespath <- function(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R", no_recursivity = F) {
# Construire l'URL de l'API GitHub
repo <- gsub(pattern = "/$", replacement = "", repo)
if (grepl("^https?://",repo)) {
api_url <- paste0(repo, "?recursive=1")
base_url <- repo
} else {
base_url <-paste0("https://api.github.com/repos/", repo, "/git/trees/", branch)
api_url <- paste0(base_url, "?recursive=1")
}
# Lire le JSON depuis GitHub
json_data <- tryCatch({
paste(readLines(api_url, warn = FALSE), collapse = "")
}, error = function(e) {
warning("Erreur lors de la récupération des données. Vérifiez l'URL ou les permissions d'accès.")
return(NULL)
})
# Vérifier si la réponse contient des fichiers
if (is.null(json_data) || !grepl('"path":', json_data)) {
stop("Aucun fichier trouvé. Vérifiez le repo ou le pattern utilisé.")
}
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(pattern = paste0('"path":"([^"]+', pattern, ')"'), json_data, ignore.case = TRUE)))
file_paths <- gsub('"path":"', "", file_paths)  # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)         # Nettoyer les guillemets restants
# Construire les URLs complètes des fichiers bruts
raw_urls <- paste0(base_url, "/", file_paths)
if(length(raw_urls) == 1) {# recursivity one time only
if(!no_recursivity) return(get_github_filespath(repo = raw_urls, no_recursivity = T) )  }
return(raw_urls)
}
url1 <- get_github_filespath(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R$")
url1
tools::showNonASCIIfile
tools::showNonASCIIfile()
tools::showNonASCIIfile("R/get_github_filespath.R")
#' @return A character vector of URLs pointing to the raw content of the matching files.
#' @examples
#' \dontrun{
#' url1 <- get_github_filespath(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R$")
#' urls <- get_github_filespath(repo = "https://api.github.com/repos/tidyverse/ggplot2/git/trees/main")
#' }
#' @export
get_github_filespath <- function(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R", no_recursivity = F) {
# Construire l'URL de l'API GitHub
repo <- gsub(pattern = "/$", replacement = "", repo)
if (grepl("^https?://",repo)) {
api_url <- paste0(repo, "?recursive=1")
base_url <- repo
} else {
base_url <-paste0("https://api.github.com/repos/", repo, "/git/trees/", branch)
api_url <- paste0(base_url, "?recursive=1")
}
# Lire le JSON depuis GitHub
json_data <- tryCatch({
paste(readLines(api_url, warn = FALSE), collapse = "")
}, error = function(e) {
warning("Error getting data from github. You should verify url or permission.")
return(NULL)
})
# Vérifier si la réponse contient des fichiers
if (is.null(json_data) || !grepl('"path":', json_data)) {
stop("No files. You should verify repo or pattern.")
}
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(pattern = paste0('"path":"([^"]+', pattern, ')"'), json_data, ignore.case = TRUE)))
file_paths <- gsub('"path":"', "", file_paths)  # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)         # Nettoyer les guillemets restants
# Construire les URLs complètes des fichiers bruts
raw_urls <- paste0(base_url, "/", file_paths)
if(length(raw_urls) == 1) {# recursivity one time only
if(!no_recursivity) return(get_github_filespath(repo = raw_urls, no_recursivity = T) )  }
return(raw_urls)
}
paths <- get_github_filespath(repo = "tidyverse/readr")
paths
`net <- get_text_network_from_files(paths,   regex_to_exclude_files_path = "test-")`
net <- get_text_network_from_files(paths,   regex_to_exclude_files_path = "test-")
raw_urls
repo
#' @return A character vector of URLs pointing to the raw content of the matching files.
#' @examples
#' \dontrun{
#' url1 <- get_github_filespath(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R$")
#' urls <- get_github_filespath(repo = "https://api.github.com/repos/tidyverse/ggplot2/git/trees/main")
#' }
#' @export
get_github_filespath <- function(repo = "tidyverse/ggplot2", branch = "main", pattern = "\\.R", no_recursivity = F) {
# Construire l'URL de l'API GitHub
repo <- gsub(pattern = "/$", replacement = "", repo)
if (grepl("^https?://",repo)) {
api_url <- paste0(repo, "?recursive=1")
base_url <- repo
} else {
base_url <-paste0("https://api.github.com/repos/", repo, "/git/trees/", branch)
api_url <- paste0(base_url, "?recursive=1")
}
# Lire le JSON depuis GitHub
json_data <- tryCatch({
paste(readLines(api_url, warn = FALSE), collapse = "")
}, error = function(e) {
warning("Error getting data from github. You should verify url or permission.")
return(NULL)
})
# Vérifier si la réponse contient des fichiers
if (is.null(json_data) || !grepl('"path":', json_data)) {
stop("No files. You should verify repo or pattern.")
}
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(pattern = paste0('"path":"([^"]+', pattern, ')"'), json_data, ignore.case = TRUE)))
file_paths <- gsub('"path":"', "", file_paths)  # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)         # Nettoyer les guillemets restants
# Construire les URLs complètes des fichiers bruts
# raw_urls <- paste0(base_url, "/", file_paths)
raw_urls <- paste0( "https://raw.githubusercontent.com/" , repo, "/", branch, "/", file_paths)
if(length(raw_urls) == 1) {# recursivity one time only
if(!no_recursivity) return(get_github_filespath(repo = raw_urls, no_recursivity = T) )  }
return(raw_urls)
}
urls <- get_github_filespath(repo = "https://api.github.com/repos/tidyverse/ggplot2/git/trees/main")
urls
#' @param branch **(character)** The branch to scan for files. Default is `"main"`.
#' @param pattern **(character)** A regex pattern to filter files (default is `"\\.R"`, meaning R scripts).
#'
#' @return A character vector of URLs pointing to the raw content of the matching files.
#' @export
#'
#' @examples
#' \dontrun{
#' readr_fp <- get_rawhub_filespath(repo = "tidyverse/readr", pattern = "\\.R")
#' }
get_rawgithub_filespath <- function(repo = "tidyverse/ggplot", branch = "main", pattern = "\\.R") {
# construct an url to api.github :
if (grepl("^https?://", repo)) {
direct_access = T# we retrieve that hereafter for crafting the url!
api_url <- paste0(repo,  "?recursive=1")  #use URL passed
} else {direct_access = F
api_url <- paste0("https://api.github.com/repos/",repo, "/git/trees/", branch, "?recursive=1") }
# Lire le JSON en texte brut
json_data <- paste(readLines(api_url, warn = FALSE), collapse = "")
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(ignore.case = T , pattern = paste0('"path":"[^"]+', pattern, '"'), text = json_data)))
file_paths <- gsub('"path":"', "", file_paths) # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)       # Nettoyer les guillemets restants
# Construire les URLs complètes des fichiers bruts
raw_urls <- paste0( "https://raw.githubusercontent.com/" , repo, "/", branch, "/", file_paths)
if(direct_access){ raw_urls <- paste0( repo ,file_paths) }
return(raw_urls)
}
readr_fp <- get_rawhub_filespath(repo = "tidyverse/readr", pattern = "\\.R")
#' @param branch **(character)** The branch to scan for files. Default is `"main"`.
#' @param pattern **(character)** A regex pattern to filter files (default is `"\\.R"`, meaning R scripts).
#'
#' @return A character vector of URLs pointing to the raw content of the matching files.
#' @export
#'
#' @examples
#' \dontrun{
#' readr_fp <- get_rawhub_filespath(repo = "tidyverse/readr", pattern = "\\.R")
#' }
get_rawgithub_filespath <- function(repo = "tidyverse/ggplot", branch = "main", pattern = "\\.R") {
# construct an url to api.github :
if (grepl("^https?://", repo)) {
direct_access = T# we retrieve that hereafter for crafting the url!
api_url <- paste0(repo,  "?recursive=1")  #use URL passed
} else {direct_access = F
api_url <- paste0("https://api.github.com/repos/",repo, "/git/trees/", branch, "?recursive=1") }
# Lire le JSON en texte brut
json_data <- paste(readLines(api_url, warn = FALSE), collapse = "")
# Extraire les fichiers correspondant au pattern
file_paths <- unlist(regmatches(json_data, gregexpr(ignore.case = T , pattern = paste0('"path":"[^"]+', pattern, '"'), text = json_data)))
file_paths <- gsub('"path":"', "", file_paths) # Supprimer le préfixe "path"
file_paths <- gsub('"', "", file_paths)       # Nettoyer les guillemets restants
# Construire les URLs complètes des fichiers bruts
raw_urls <- paste0( "https://raw.githubusercontent.com/" , repo, "/", branch, "/", file_paths)
if(direct_access){ raw_urls <- paste0( repo ,file_paths) }
return(raw_urls)
}
readr_fp <- get_rawgithub_filespath(repo = "tidyverse/readr", pattern = "\\.R")
readr_fp
`net <- get_text_network_from_files(readr_fp,   regex_to_exclude_files_path = "test-")`
net <- get_text_network_from_files(readr_fp,   regex_to_exclude_files_path = "test-")
# In that case, don't forget to commit and push the resulting figure files, so they display on GitHub and CRAN.
devtools::build_readme()
